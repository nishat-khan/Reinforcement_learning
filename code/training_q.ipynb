{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning example for the motion of an driving agent on a straight road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete State Space\n",
    "-   see simple_road_env.py\n",
    "\n",
    "Action Space:\n",
    "-\t“Maintain” current lane and speed,\n",
    "-\t“Accelerate” at rate = a1[m/s2], provided velocity does not exceed vmax[km/h],\n",
    "-\t“Decelerate” at rate = −a1[m/s2], provided velocity is above vmin[km/h],\n",
    "-\t“Hard Accelerate” at rate = a2[m/s2], provided velocity does not exceed vmax[km/h],\n",
    "-\t“Hard Decelerate” at rate = −a2[m/s2], provided velocity is above vmin[km/h],\n",
    "(acceleration are given for a constant amount this time step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time  # to time the learning process\n",
    "import json  # to get the configuration of the environment\n",
    "from env.simple_road_env import Road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training_agent import train_agent\n",
    "from models.simple_brains import QLearningTable\n",
    "from models.simple_brains import DP\n",
    "from models.simple_DQN_tensorflow import DeepQNetwork\n",
    "from utils.visualization import display_results\n",
    "from collections import deque\n",
    "import math\n",
    "from utils.logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = np.random.seed(0)\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "np.set_printoptions(formatter={'float': lambda x: f\"{x:0.2f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset_q_table - self.q_table has shape = (0, 7)\n",
      "hyper_parameters = ('q', 0.99, 0.02, 1.0, 0.01, 0.998466)\n",
      "\n",
      " --- Episode=0 ---\n",
      " eps=0.998466\n",
      " Average Score in returns_window = -77.00 \n",
      " duration=0.06\n",
      "Episode 1 / 7000. Eps = 0.998466. Total_steps = 7. Return = -77. Max return = -inf, Top 10 = [-77]\n",
      "Episode 21 / 7000. Eps = 0.9682753947729185. Total_steps = 8. Return = -44. Max return = 14, Top 10 = [14, -24, -44, -44, -66, -76, -77, -77, -86, -90]\n",
      "Episode 41 / 7000. Eps = 0.9389976625369826. Total_steps = 10. Return = -84. Max return = 14, Top 10 = [14, -24, -44, -44, -66, -70, -76, -77, -77, -82]\n",
      "Episode 61 / 7000. Eps = 0.9106052007618131. Total_steps = 15. Return = -111. Max return = 14, Top 10 = [14, -24, -30, -43, -44, -44, -66, -67, -70, -72]\n",
      "Episode 81 / 7000. Eps = 0.8830712415344311. Total_steps = 8. Return = 8. Max return = 14, Top 10 = [14, 8, -14, -18, -19, -24, -30, -43, -44, -44]\n",
      "\n",
      " --- Episode=100 ---\n",
      " eps=0.8563698263229421\n",
      " Average Score in returns_window = -110.22 \n",
      " duration=5.04\n",
      "Episode 101 / 7000. Eps = 0.8563698263229421. Total_steps = 10. Return = -170. Max return = 14, Top 10 = [14, 8, -4, -6, -14, -18, -19, -24, -30, -43]\n",
      "Episode 121 / 7000. Eps = 0.8304757815032884. Total_steps = 6. Return = -70. Max return = 14, Top 10 = [14, 10, 8, -4, -5, -6, -6, -7, -14, -18]\n",
      "Episode 141 / 7000. Eps = 0.8053646946260007. Total_steps = 6. Return = -156. Max return = 14, Top 10 = [14, 10, 10, 8, -4, -4, -5, -6, -6, -7]\n",
      "Episode 161 / 7000. Eps = 0.7810128914005703. Total_steps = 5. Return = -59. Max return = 14, Top 10 = [14, 14, 10, 10, 10, 8, -4, -4, -5, -6]\n",
      "Episode 181 / 7000. Eps = 0.7573974133757441. Total_steps = 8. Return = -40. Max return = 14, Top 10 = [14, 14, 10, 10, 10, 10, 8, -4, -4, -5]\n",
      "\n",
      " --- Episode=200 ---\n",
      " eps=0.7344959962947019\n",
      " Average Score in returns_window = -88.42 \n",
      " duration=10.81\n",
      "Episode 201 / 7000. Eps = 0.7344959962947019. Total_steps = 9. Return = -81. Max return = 17, Top 10 = [17, 14, 14, 10, 10, 10, 10, 8, -4, -4]\n",
      "Episode 221 / 7000. Eps = 0.7122870491047069. Total_steps = 5. Return = -63. Max return = 17, Top 10 = [17, 14, 14, 10, 10, 10, 10, 8, 3, 0]\n",
      "Episode 241 / 7000. Eps = 0.6907496336014416. Total_steps = 9. Return = -93. Max return = 17, Top 10 = [17, 14, 14, 10, 10, 10, 10, 8, 3, 0]\n",
      "Episode 261 / 7000. Eps = 0.6698634446888371. Total_steps = 13. Return = -23. Max return = 18, Top 10 = [18, 17, 14, 14, 14, 10, 10, 10, 10, 8]\n",
      "Episode 281 / 7000. Eps = 0.6496087912357864. Total_steps = 11. Return = -131. Max return = 18, Top 10 = [18, 17, 14, 14, 14, 10, 10, 10, 10, 8]\n",
      "\n",
      " --- Episode=300 ---\n",
      " eps=0.6299665775116924\n",
      " Average Score in returns_window = -63.49 \n",
      " duration=16.50\n",
      "Episode 301 / 7000. Eps = 0.6299665775116924. Total_steps = 14. Return = -38. Max return = 18, Top 10 = [18, 17, 14, 14, 14, 10, 10, 10, 10, 8]\n",
      "Episode 321 / 7000. Eps = 0.6109182851833495. Total_steps = 13. Return = -35. Max return = 18, Top 10 = [18, 17, 17, 14, 14, 14, 10, 10, 10, 10]\n",
      "Episode 341 / 7000. Eps = 0.5924459558561853. Total_steps = 13. Return = -23. Max return = 18, Top 10 = [18, 17, 17, 17, 14, 14, 14, 10, 10, 10]\n",
      "Episode 361 / 7000. Eps = 0.574532174143403. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 17, 17, 17, 17, 14, 14, 14, 14, 10]\n",
      "Episode 381 / 7000. Eps = 0.5571600512470597. Total_steps = 7. Return = 3. Max return = 18, Top 10 = [18, 17, 17, 17, 17, 14, 14, 14, 14, 10]\n",
      "\n",
      " --- Episode=400 ---\n",
      " eps=0.5403132090356066\n",
      " Average Score in returns_window = -57.31 \n",
      " duration=22.49\n",
      "Episode 401 / 7000. Eps = 0.5403132090356066. Total_steps = 4. Return = -134. Max return = 18, Top 10 = [18, 17, 17, 17, 17, 14, 14, 14, 14, 10]\n",
      "Episode 421 / 7000. Eps = 0.5239757646028751. Total_steps = 6. Return = 10. Max return = 18, Top 10 = [18, 17, 17, 17, 17, 14, 14, 14, 14, 14]\n",
      "Episode 441 / 7000. Eps = 0.5081323152939513. Total_steps = 6. Return = -64. Max return = 18, Top 10 = [18, 18, 18, 17, 17, 17, 17, 14, 14, 14]\n",
      "Episode 461 / 7000. Eps = 0.49276792418382576. Total_steps = 8. Return = -78. Max return = 18, Top 10 = [18, 18, 18, 17, 17, 17, 17, 17, 17, 14]\n",
      "Episode 481 / 7000. Eps = 0.4778681059951218. Total_steps = 5. Return = -19. Max return = 18, Top 10 = [18, 18, 18, 17, 17, 17, 17, 17, 17, 17]\n",
      "\n",
      " --- Episode=500 ---\n",
      " eps=0.46341881344163294\n",
      " Average Score in returns_window = -44.22 \n",
      " duration=27.95\n",
      "Episode 501 / 7000. Eps = 0.46341881344163294. Total_steps = 11. Return = -53. Max return = 18, Top 10 = [18, 18, 18, 18, 17, 17, 17, 17, 17, 17]\n",
      "Episode 521 / 7000. Eps = 0.4494064239847872. Total_steps = 9. Return = -3. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 17, 17, 17, 17]\n",
      "Episode 541 / 7000. Eps = 0.4358177269905588. Total_steps = 8. Return = 0. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 17, 17, 17, 17]\n",
      "Episode 561 / 7000. Eps = 0.4226399112747146. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 17, 17, 17]\n",
      "Episode 581 / 7000. Eps = 0.4098605530246553. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 17]\n",
      "\n",
      " --- Episode=600 ---\n",
      " eps=0.3974676040864635\n",
      " Average Score in returns_window = -37.56 \n",
      " duration=33.95\n",
      "Episode 601 / 7000. Eps = 0.3974676040864635. Total_steps = 6. Return = 14. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 17]\n",
      "Episode 621 / 7000. Eps = 0.3854493806061162. Total_steps = 6. Return = 14. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 641 / 7000. Eps = 0.3737945520141537. Total_steps = 9. Return = -3. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 661 / 7000. Eps = 0.3624921303434176. Total_steps = 11. Return = -91. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 681 / 7000. Eps = 0.35153145986978906. Total_steps = 8. Return = -166. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=700 ---\n",
      " eps=0.3409022070661599\n",
      " Average Score in returns_window = -30.81 \n",
      " duration=40.45\n",
      "Episode 701 / 7000. Eps = 0.3409022070661599. Total_steps = 12. Return = -20. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 721 / 7000. Eps = 0.33059435086016464. Total_steps = 6. Return = -72. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 741 / 7000. Eps = 0.3205981731864907. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 761 / 7000. Eps = 0.3109042498248572. Total_steps = 6. Return = -64. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 781 / 7000. Eps = 0.3015034415150256. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=800 ---\n",
      " eps=0.29238688534046714\n",
      " Average Score in returns_window = -30.18 \n",
      " duration=46.34\n",
      "Episode 801 / 7000. Eps = 0.29238688534046714. Total_steps = 7. Return = -79. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 821 / 7000. Eps = 0.28354598637256034. Total_steps = 8. Return = -4. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 841 / 7000. Eps = 0.27497240956744384. Total_steps = 9. Return = -7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 861 / 7000. Eps = 0.2666580719078841. Total_steps = 6. Return = -66. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 881 / 7000. Eps = 0.2585951347827485. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=900 ---\n",
      " eps=0.2507759965969014\n",
      " Average Score in returns_window = -17.04 \n",
      " duration=51.63\n",
      "Episode 901 / 7000. Eps = 0.2507759965969014. Total_steps = 8. Return = 8. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 921 / 7000. Eps = 0.2431932856045542. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 941 / 7000. Eps = 0.2358398529593124. Total_steps = 7. Return = 7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 961 / 7000. Eps = 0.22870876597436998. Total_steps = 6. Return = 6. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 981 / 7000. Eps = 0.22179330158649377. Total_steps = 11. Return = -9. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1000 ---\n",
      " eps=0.21508694001763823\n",
      " Average Score in returns_window = -8.36 \n",
      " duration=57.10\n",
      "Episode 1001 / 7000. Eps = 0.21508694001763823. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1021 / 7000. Eps = 0.20858335862821334. Total_steps = 7. Return = 11. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1041 / 7000. Eps = 0.20227642595621134. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1061 / 7000. Eps = 0.19616019593657225. Total_steps = 13. Return = -15. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1081 / 7000. Eps = 0.19022890229533854. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1100 ---\n",
      " eps=0.1844769531133137\n",
      " Average Score in returns_window = -4.42 \n",
      " duration=62.66\n",
      "Episode 1101 / 7000. Eps = 0.1844769531133137. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1121 / 7000. Eps = 0.17889892555409898. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1141 / 7000. Eps = 0.17348956075153893. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1161 / 7000. Eps = 0.16824375885175516. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1181 / 7000. Eps = 0.16315657420509352. Total_steps = 7. Return = 7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1200 ---\n",
      " eps=0.15822321070345294\n",
      " Average Score in returns_window = 2.56 \n",
      " duration=68.02\n",
      "Episode 1201 / 7000. Eps = 0.15822321070345294. Total_steps = 6. Return = -68. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1221 / 7000. Eps = 0.1534390172585992. Total_steps = 7. Return = 7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1241 / 7000. Eps = 0.14879948341720073. Total_steps = 7. Return = 11. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1261 / 7000. Eps = 0.14430023510845272. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1281 / 7000. Eps = 0.13993703052028011. Total_steps = 7. Return = 7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1300 ---\n",
      " eps=0.13570575610023192\n",
      " Average Score in returns_window = 0.10 \n",
      " duration=73.57\n",
      "Episode 1301 / 7000. Eps = 0.13570575610023192. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1321 / 7000. Eps = 0.1316024226772964. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1341 / 7000. Eps = 0.12762316170098095. Total_steps = 7. Return = 3. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1361 / 7000. Eps = 0.1237642215941107. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1381 / 7000. Eps = 0.12002196421590766. Total_steps = 6. Return = -26. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1400 ---\n",
      " eps=0.1163928614320158\n",
      " Average Score in returns_window = 0.88 \n",
      " duration=78.93\n",
      "Episode 1401 / 7000. Eps = 0.1163928614320158. Total_steps = 7. Return = 11. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1421 / 7000. Eps = 0.11287349178823784. Total_steps = 7. Return = 7. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1441 / 7000. Eps = 0.10946053728484871. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1461 / 7000. Eps = 0.10615078024844375. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1481 / 7000. Eps = 0.10294110029837288. Total_steps = 7. Return = 11. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1500 ---\n",
      " eps=0.09982847140490068\n",
      " Average Score in returns_window = 7.28 \n",
      " duration=84.31\n",
      "Episode 1501 / 7000. Eps = 0.09982847140490068. Total_steps = 5. Return = -59. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1521 / 7000. Eps = 0.09680995903631892. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1541 / 7000. Eps = 0.09388271739232157. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1561 / 7000. Eps = 0.09104398672103454. Total_steps = 6. Return = 14. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1581 / 7000. Eps = 0.0882910907171702. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1600 ---\n",
      " eps=0.08562143399885376\n",
      " Average Score in returns_window = 9.34 \n",
      " duration=89.57\n",
      "Episode 1601 / 7000. Eps = 0.08562143399885376. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1621 / 7000. Eps = 0.08303249966074311. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1641 / 7000. Eps = 0.08052184690113455. Total_steps = 6. Return = 14. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1661 / 7000. Eps = 0.0780871087208183. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1681 / 7000. Eps = 0.0757259896915129. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1700 ---\n",
      " eps=0.07343626379177617\n",
      " Average Score in returns_window = 6.27 \n",
      " duration=94.95\n",
      "Episode 1701 / 7000. Eps = 0.07343626379177617. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1721 / 7000. Eps = 0.07121577230835129. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1741 / 7000. Eps = 0.0690624218009698. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1761 / 7000. Eps = 0.06697418212869327. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1781 / 7000. Eps = 0.06494908453593193. Total_steps = 6. Return = -22. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "\n",
      " --- Episode=1800 ---\n",
      " eps=0.06298521979633673\n",
      " Average Score in returns_window = 8.47 \n",
      " duration=100.41\n",
      "Episode 1801 / 7000. Eps = 0.06298521979633673. Total_steps = 7. Return = 11. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1821 / 7000. Eps = 0.06108073641281424. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1841 / 7000. Eps = 0.05923383887196786. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1861 / 7000. Eps = 0.05744278595131943. Total_steps = 6. Return = 18. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n",
      "Episode 1881 / 7000. Eps = 0.05570588907771528. Total_steps = 5. Return = 17. Max return = 18, Top 10 = [18, 18, 18, 18, 18, 18, 18, 18, 18, 18]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d611055cb067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m                         \u001b[0mwindow_success_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold_success_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns_list_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                         \u001b[0msteps_counter_list_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_info_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                         max_nb_episodes_training, max_nb_steps_training, sleep_time_between_steps_learning)\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             display_results(brain_agent, method_used, returns_list_res, window_success_res,\n",
      "\u001b[0;32m<ipython-input-21-23dfd7a16370>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(using_tkinter, agent, method, gamma, learning_rate, eps_start, eps_end, eps_decay, window_success, threshold_success, returns_list, steps_counter_list, info_training, max_nb_episodes, max_nb_steps, sleep_time, folder_name)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"q\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"expected_sarsa\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"simple_dqn_pytorch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mcurrent_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_actions_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                     \u001b[0mnext_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_actions_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mreturn_of_episode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/summer_2/RL/RL-self-driving-car/code/models/simple_brains.py\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, observation, masked_actions_list, greedy_epsilon)\u001b[0m\n\u001b[1;32m     90\u001b[0m             state_action = self.q_table.loc[\n\u001b[1;32m     91\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_features_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_features_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# & (self.q_table[self.state_features_list[2]] == observation[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 ]\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_other_int_dtype\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfill_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0movalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0mfill_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m     \u001b[0mfill_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   4343\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4344\u001b[0m             \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4345\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4346\u001b[0m         )\n\u001b[1;32m   4347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6257\u001b[0m                 new_data = self._data.fillna(\n\u001b[0;32m-> 6258\u001b[0;31m                     \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6259\u001b[0m                 )\n\u001b[1;32m   6260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fillna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     def replace(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block_same_class\u001b[0;34m(self, values, placement, ndim, dtype)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         return make_block(\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         )\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   3265\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3267\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             raise ValueError(\n\u001b[1;32m    127\u001b[0m                 \u001b[0;34m\"Wrong number of items passed {val}, placement implies \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actions_list = [\"no_change\", \"speed_up\", \"speed_up_up\", \"slow_down\", \"slow_down_down\"]\n",
    "state_features_list = [\"position\", \"velocity\"]  # , \"obstacle_position\"]\n",
    "\n",
    "# the environment\n",
    "flag_tkinter = False\n",
    "initial_state = [0, 3, 12]\n",
    "goal_velocity = 3\n",
    "env = Road(flag_tkinter, actions_list, state_features_list, initial_state, goal_velocity)\n",
    "\n",
    "# getting the configuration of the test\n",
    "env_configuration = vars(env)\n",
    "dict_configuration = dict(env_configuration)\n",
    "\n",
    "# avoid special types:\n",
    "not_to_consider = [\"tk\", \"children\", \"canvas\", \"_tclCommands\", \"master\", \"_tkloaded\", \"colour_action_code\",\n",
    "                   \"colour_velocity_code\", \"origin_coord\", \"display_canvas\", \"origin\", \"_last_child_ids\", \"rect\",\n",
    "                   \"logger\"]\n",
    "for elem in not_to_consider:\n",
    "    if elem in dict_configuration:\n",
    "        del dict_configuration[elem]\n",
    "# saving the configuration in a json\n",
    "with open('env/simple_road_env_configuration.json', 'w') as outfile:\n",
    "    json.dump(dict_configuration, outfile)\n",
    "\n",
    "# Different possible algorithms to update the state-action table:\n",
    "\n",
    "# -1- Temporal-Difference  # all are working - \"q\" performs the best\n",
    "method_used = \"q\"\n",
    "\n",
    "# Instanciate an Agent\n",
    "brain_agent = None\n",
    "brain_agent = QLearningTable(actions=actions_list, state=state_features_list, load_q_table=False)\n",
    "\n",
    "# Training and/or Testing\n",
    "flag_training_once = True\n",
    "flag_testing = False\n",
    "flag_training_hyper_parameter_tuning = False  # Tkinter is not used when tuning hyper-parameters\n",
    "display_learning_results = False  # only used for training_once\n",
    "\n",
    "# for testing\n",
    "max_nb_steps_testing = 50\n",
    "nb_tests = 10\n",
    "sleep_time_between_steps_testing = 0.5  # slow to see the steps\n",
    "\n",
    "# for learning\n",
    "# hyper-parameters\n",
    "gamma_learning = 0.99\n",
    "learning_rate_learning = 0.02\n",
    "eps_start_learning = 1.0\n",
    "eps_end_training = 0.01\n",
    "# reach eps_end at episode_id = log10(eps_end/eps_start) / log10(eps_decay)\n",
    "# 0.99907 for 5000 at 0.01/1.0\n",
    "eps_decay_training = 0.998466\n",
    "# eps_decay_training = 0.99907  # - when 70000 episode\n",
    "# 0.99907  # for getting to 0.01 in ~5000 episodes\n",
    "\n",
    "# to reach eps_end at episode episode_id, eps_decay = (eps_end / eps_start) ** (1/episode_id)\n",
    "max_nb_episodes_training = 7000\n",
    "max_nb_steps_training = 25\n",
    "sleep_time_between_steps_learning = 0.0005\n",
    "\n",
    "# success conditions\n",
    "window_success_res = 100\n",
    "threshold_success_training = 17\n",
    "dict_info_training = {}\n",
    "# 22.97 for self.reward = 1 + self.reward / max(self.rewards_dict.values())\n",
    "# q_max = 9.23562904132267 for expected_sarsa\n",
    "\n",
    "if flag_training_hyper_parameter_tuning:\n",
    "\n",
    "    # No tkinter used\n",
    "    learning_rate_list = [0.003, 0.01, 0.03, 0.1, 0.3, 1]\n",
    "\n",
    "    gamma_learning_list = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n",
    "    nb_episodes_to_plateau_list = [300, 500, 800, 1000, 3000, 5000]\n",
    "    # [0.954992586021, 0.9847666521101, 0.995405417351, 0.998466120868, 0.9995395890030, 0.9999846495505]\n",
    "    eps_decay_list = [(eps_end_training / eps_start_learning) ** (1/nb) for nb in nb_episodes_to_plateau_list]\n",
    "\n",
    "    for i, param in enumerate(eps_decay_list):\n",
    "        brain_agent.reset_q_table()  # re-initialize the model!!\n",
    "\n",
    "        folder_name_training = str(i) + '/'\n",
    "        logger_name = str(i) + '.log'\n",
    "        logger = Logger(folder_name_training, logger_name, 0)\n",
    "\n",
    "        hyper_parameters = (\n",
    "            method_used,\n",
    "            gamma_learning,\n",
    "            learning_rate_learning,\n",
    "            eps_start_learning,\n",
    "            eps_end_training,\n",
    "            param  # decay\n",
    "        )\n",
    "        logger.log(str(hyper_parameters), 1)\n",
    "        # after = Register an alarm callback that is called after a given time.\n",
    "        # give results as reference\n",
    "        returns_list_res, steps_counter_list_res = [], []\n",
    "        dict_info_training = {}\n",
    "\n",
    "        train_agent(flag_tkinter, brain_agent, *hyper_parameters,\n",
    "                    window_success_res, threshold_success_training, returns_list_res,\n",
    "                    steps_counter_list_res, dict_info_training,\n",
    "                    max_nb_episodes_training, max_nb_steps_training, sleep_time_between_steps_learning,\n",
    "                    folder_name_training)\n",
    "        logger.log(dict_info_training, 1)\n",
    "\n",
    "        try:\n",
    "            display_results(brain_agent, method_used, returns_list_res, window_success_res,\n",
    "                            threshold_success_training, steps_counter_list_res,\n",
    "                            display_flag=False, folder_name=folder_name_training)\n",
    "        except Exception as e:\n",
    "            print('Exception = {}'.format(e))\n",
    "\n",
    "        # testing\n",
    "        returns_list_testing = []  # passed as a reference\n",
    "        test_agent(flag_tkinter, brain_agent, returns_list_testing, nb_tests, max_nb_steps_testing,\n",
    "                   sleep_time_between_steps_learning, folder_name_training + \"q_table.pkl\")\n",
    "        logger.log(returns_list_testing, 1)\n",
    "\n",
    "if flag_training_once:\n",
    "    hyper_parameters = (\n",
    "        method_used,\n",
    "        gamma_learning,\n",
    "        learning_rate_learning,\n",
    "        eps_start_learning,\n",
    "        eps_end_training,\n",
    "        eps_decay_training\n",
    "    )\n",
    "    print(\"hyper_parameters = {}\".format(hyper_parameters))\n",
    "    returns_list_res, steps_counter_list_res = [], []\n",
    "    if flag_tkinter:\n",
    "        # after(self, time [ms] before execution of func(*args), func=None, *args):\n",
    "        # !! callback function. No return value can be read\n",
    "        env.after(100, train_agent, flag_tkinter, brain_agent,\n",
    "                  *hyper_parameters,\n",
    "                  window_success_res, threshold_success_training, returns_list_res,\n",
    "                  steps_counter_list_res, dict_info_training,\n",
    "                  max_nb_episodes_training, max_nb_steps_training, sleep_time_between_steps_learning)\n",
    "        env.mainloop()\n",
    "        print(\"returns_list_res = {}, window_success_res = {}, steps_counter_list_res = {}\".format(\n",
    "            returns_list_res, window_success_res, steps_counter_list_res))\n",
    "    else:\n",
    "        train_agent(flag_tkinter, brain_agent, *hyper_parameters,\n",
    "                    window_success_res, threshold_success_training, returns_list_res,\n",
    "                    steps_counter_list_res, dict_info_training,\n",
    "                    max_nb_episodes_training, max_nb_steps_training, sleep_time_between_steps_learning)\n",
    "    try:\n",
    "        display_results(brain_agent, method_used, returns_list_res, window_success_res,\n",
    "                        threshold_success_training, steps_counter_list_res,\n",
    "                        display_flag=display_learning_results)\n",
    "    except Exception as e:\n",
    "        print('Exception = {}'.format(e))\n",
    "    print(\"hyper_parameters = {}\".format(hyper_parameters))\n",
    "\n",
    "    # print(brain_agent.reference_list)\n",
    "\n",
    "if flag_testing:\n",
    "    returns_list_testing = []\n",
    "    if flag_tkinter:\n",
    "        env.after(100, test_agent, flag_tkinter, brain_agent, returns_list_testing, nb_tests, max_nb_steps_testing,\n",
    "                  sleep_time_between_steps_testing)\n",
    "        env.mainloop()\n",
    "    else:\n",
    "        test_agent(flag_tkinter, brain_agent, returns_list_testing, nb_tests, max_nb_steps_testing,\n",
    "                   sleep_time_between_steps_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
